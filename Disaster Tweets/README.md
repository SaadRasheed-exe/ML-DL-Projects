# Disaster Tweets

The dataset can be found [here](https://www.kaggle.com/competitions/nlp-getting-started).\
Multiple models were built and trained for this project.

1. [Naive Bayes](https://scikit-learn.org/stable/modules/naive_bayes.html) (Base Model)
2. Feed-Forward Network
3. [Recurrent Neural Network](https://en.wikipedia.org/wiki/Recurrent_neural_network) (with [LSTM](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM) Layers)
4. Recurrent Neural Network (with [GRU](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU) Layers)
5. [Bi-directional](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Bidirectional) RNN (with LSTM Layers)
6. 1-Dimensional Convolutional Neural Network
7. Feed-Forward Neural Network with Universal Sentence Encoder.

According to Kaggle, accuracy of the feed-forward network with universal sentence encodings is 81.4%.

![Kaggle Result](https://github.com/SaadRasheed-exe/ML-DL-Projects/blob/main/Disaster%20Tweets/kaggle%20result.jpg?raw=true)
